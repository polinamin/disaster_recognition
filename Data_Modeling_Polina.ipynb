{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6e615-1649-4923-8806-b56d08120f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kalpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15ffa1-b197-4074-8022-ac61c784f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arjun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca306377-579d-4764-a667-6103084e4ee7",
   "metadata": {},
   "source": [
    "## Polina's Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b131b0-d0e9-41ae-8938-85cdc7811baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import export_text, DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be4870b-bc6d-4092-a904-99417dd5d551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4286c22-6a2a-4c73-aef9-36592eaeac83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Gensim.\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "accabe16-56ad-4a3a-b2d0-b3752515e1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/polinaminkovski/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8f27eb4-8566-4d44-aba2-464ffe90404d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6da64a-b54e-4ae8-be02-cbebb5af1d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('training.pkl', 'rb') as file: \n",
    "      \n",
    "    df_train = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dafe08b0-1c4a-4714-b3f9-429651db2c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('testing.pkl', 'rb') as file: \n",
    "      \n",
    "    df_test = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ef34981-a12e-469c-be28-2aec2b002331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a9bb0-56a1-4b22-b9eb-ebd58c1ecf1f",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa98fabe-cede-4cf4-b449-9ae356812164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[\"text_lower\"] = df_train['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0d33cd12-2aee-4e63-bbb8-337d0d03cd25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['tokenized_lower_no_char'] = df_train['text_lower'].str.replace('[^a-zA-Z0-9\\s]+',\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2401bb00-4f19-41ea-8494-9cc91bbf27fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['tokenized_text'] = df_train.apply(lambda row: nltk.word_tokenize(row['tokenized_lower_no_char']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ad43a78c-8ef4-4935-8575-41f4441e7cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "labels = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "  labels.append(row['target'])\n",
    "\n",
    "  token_list = [x for x in row['tokenized_text'] if x not in stopwords.words('english')]\n",
    "\n",
    "  tweets.append(\" \".join(token_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "85189db3-8793-4340-9272-c19f7ef98c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['split_text'] = [sentence.split() for sentence in df_train[\"tokenized_lower_no_char\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "abe2b857-91a4-4de2-abea-5823699973cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_w2v = df_train['split_text']\n",
    "with open('X_w2v.pkl', 'wb') as file: \n",
    "      \n",
    "    # A new file will be created \n",
    "    pickle.dump(X_w2v, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45103d3-05ea-4485-bb18-580b8ae3867f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a466085-7382-4c10-b9fc-068ce3db0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training.pkl', 'wb') as file: \n",
    "      \n",
    "    # A new file will be created \n",
    "    pickle.dump(df_train, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e652dd12-4fbe-46e1-9dae-771fa9b95b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = gensim.models.KeyedVectors.load_word2vec_format('lexvec.commoncrawl.300d.W.pos.vectors.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0b14e520-df3b-490c-b242-4b90fc017cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = tweets\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "38740051-87c0-47df-933d-8f01ba73e725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('X.pkl', 'wb') as file: \n",
    "      \n",
    "    # A new file will be created \n",
    "    pickle.dump(X, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "af5d4457-9e82-4781-9e31-413dcce80786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('y.pkl', 'wb') as file: \n",
    "      \n",
    "    # A new file will be created \n",
    "    pickle.dump(y, file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb838236-00ce-4125-ba1d-6267a3167444",
   "metadata": {},
   "source": [
    "### More cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "075f3f1d-cb11-4aa6-929b-a8aac5ffd0bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['lower_some_char'] = df_train['text_lower'].str.replace('[^a-zA-Z0-9#@\\s]+',\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c18e4bfc-8929-4d19-8b3e-d054ca117b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets_c = []\n",
    "labels_c = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "  labels_c.append(row['target'])\n",
    "\n",
    "  token_list = [x for x in row['lower_some_char'] if x not in stopwords.words('english')]\n",
    "\n",
    "  tweets_c.append(\" \".join(token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bb98d921-bf99-4ffd-83af-84d8034e9e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_c = tweets_c\n",
    "y_c = labels_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9dd33f75-4f6f-4377-948b-035d7781117f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('X_c.pkl', 'wb') as file: \n",
    "      \n",
    "    # A new file will be created \n",
    "    pickle.dump(X_c, file) \n",
    "    \n",
    "with open('y_c.pkl', 'wb') as file: \n",
    "      \n",
    "    # A new file will be created \n",
    "    pickle.dump(y_c, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e1128e19-de40-419b-b9a7-ee51f1e92112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "71e3d8d6-8561-415b-8754-0241605b42ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = gensim.models.Word2Vec(X_train, min_count = 1,vector_size = 100, window = 5, sg=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7d762096-fb89-402a-b372-f912f95fd49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary = list(model1.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2e53b240-4062-48e8-92da-795edd468af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize(text_):\n",
    "    words = text_\n",
    "    words_vecs = [model1.wv[word] for word in words if word in vocabulary]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f1e586ff-7d2b-4566-85bc-81e74fdeca24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_w2v = np.array([vectorize(text_) for text_ in X_train])\n",
    "with open('X_train_w2v.pkl', 'wb') as file: \n",
    "      \n",
    "    pickle.dump(X_train_w2v, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5bb92d8b-cd7d-4a13-944f-5eae2a889fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val_w2v = np.array([vectorize(text_) for text_ in X_val])\n",
    "with open('X_val_w2v.pkl', 'wb') as file: \n",
    "      \n",
    "    pickle.dump(X_val_w2v, file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
