{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "41e99efe-0971-47cd-a46b-784ab52278bb",
      "metadata": {
        "id": "41e99efe-0971-47cd-a46b-784ab52278bb"
      },
      "source": [
        "# LSTM and Glove Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13326c69-468d-4007-a531-729263151501",
      "metadata": {
        "id": "13326c69-468d-4007-a531-729263151501"
      },
      "source": [
        "Works on Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "1e3913e2-4f3e-4b59-b81a-0555c7601644",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e3913e2-4f3e-4b59-b81a-0555c7601644",
        "outputId": "f75d7f17-a8c4-4068-bfef-a349702ea789",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import pickle\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Input, Dropout, Bidirectional, Flatten, Conv1D, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim.downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just using text"
      ],
      "metadata": {
        "id": "9ZJabGEG3w8F"
      },
      "id": "9ZJabGEG3w8F"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "d137cd2d-be04-479b-924b-541702e94d58",
      "metadata": {
        "id": "d137cd2d-be04-479b-924b-541702e94d58"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train = df_train.drop(columns=['id','keyword','location'])\n",
        "test =  df_test.drop(columns=['id','keyword','location'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "8371c6d3-7f0d-47c8-ae9f-f358fc2c2ada",
      "metadata": {
        "id": "8371c6d3-7f0d-47c8-ae9f-f358fc2c2ada"
      },
      "outputs": [],
      "source": [
        "def tweet_cleaner(tweet , remove_usernames = True):\n",
        "  '''\n",
        "  made for cleaning the tweet\n",
        "\n",
        "  input: tweet: an uncleaned tweet with a 'string datatype\n",
        "         remove_usernames: bool if usernames should be included or not. even if included, @ symbol is removed\n",
        "\n",
        "  output: cleaned tweet with all stopwords removed\n",
        "\n",
        "  '''\n",
        "  #first remove usernames\n",
        "  if remove_usernames:\n",
        "    tweet = re.sub('@[^\\s]+','',tweet)\n",
        "\n",
        "  # remove urls\n",
        "  tweet = re.sub('http[^\\s]+','',tweet)\n",
        "  tweet = re.sub('https[^\\s]+','',tweet)\n",
        "  tweet = re.sub('www[^\\s]+','',tweet)\n",
        "\n",
        "  # just capture words\n",
        "  pattern = r'\\b[a-zA-Z]+\\b'\n",
        "\n",
        "  # including new stopwords unique to tweets. and adding them to nltk\n",
        "  stops = nltk.corpus.stopwords.words('english')\n",
        "  new_stop_words = [\"ha\", \"wa\", \"http\", \"s\", \"https\", \"com\", \"'s\", \"' s\", \"'ll\", \"' ll\", \"' d\", \"'d\", \"'re\", \"' re\", \"co\", \"amp\", \"url\"]\n",
        "  stops.extend(new_stop_words)\n",
        "\n",
        "  # Gets list of words from re.findall() and filters out stop words and 1 letter words\n",
        "  list_of_words = [x.lower() for x in re.findall(pattern, tweet) if (x not in stops) and (len(x)>1)]\n",
        "\n",
        "  return ' '.join(list_of_words)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['text_cleaned'] = train['text'].apply(tweet_cleaner)\n",
        "test['text_cleaned'] = test['text'].apply(tweet_cleaner)\n",
        "train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dMRkJpyH88hZ",
        "outputId": "0d6818b9-2c18-4194-d468-003046f04d04"
      },
      "id": "dMRkJpyH88hZ",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  target  \\\n",
              "3973  @crabbycale OH MY GOD THE MEMORIES ARE FLOODIN...       0   \n",
              "620   @O_Magazine satan's daughter shadow warrior in...       1   \n",
              "1257  I hope the only time I end up on TV is when I'...       1   \n",
              "6174                                     Yay for sirens       0   \n",
              "4216  DLH issues Hazardous Weather Outlook (HWO) htt...       1   \n",
              "\n",
              "                                           text_cleaned  \n",
              "3973           oh my god the memories are flooding back  \n",
              "620   satan daughter shadow warrior women aka transg...  \n",
              "1257  hope time end tv arrested lighting buildings fire  \n",
              "6174                                         yay sirens  \n",
              "4216           dlh issues hazardous weather outlook hwo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00dac65c-1f67-42ab-a9e7-0dfba34b0a9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3973</th>\n",
              "      <td>@crabbycale OH MY GOD THE MEMORIES ARE FLOODIN...</td>\n",
              "      <td>0</td>\n",
              "      <td>oh my god the memories are flooding back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>@O_Magazine satan's daughter shadow warrior in...</td>\n",
              "      <td>1</td>\n",
              "      <td>satan daughter shadow warrior women aka transg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>I hope the only time I end up on TV is when I'...</td>\n",
              "      <td>1</td>\n",
              "      <td>hope time end tv arrested lighting buildings fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6174</th>\n",
              "      <td>Yay for sirens</td>\n",
              "      <td>0</td>\n",
              "      <td>yay sirens</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4216</th>\n",
              "      <td>DLH issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "      <td>1</td>\n",
              "      <td>dlh issues hazardous weather outlook hwo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00dac65c-1f67-42ab-a9e7-0dfba34b0a9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00dac65c-1f67-42ab-a9e7-0dfba34b0a9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00dac65c-1f67-42ab-a9e7-0dfba34b0a9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70fa3fa8-c6a2-41c2-818b-e14d9fa7b619\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70fa3fa8-c6a2-41c2-818b-e14d9fa7b619')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70fa3fa8-c6a2-41c2-818b-e14d9fa7b619 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using [this](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) to map text to vectors\n"
      ],
      "metadata": {
        "id": "fI3W0Rel_DGY"
      },
      "id": "fI3W0Rel_DGY"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# i want to make the tokenizer and embedding matrix have as much information.\n",
        "# so I'm using all data availabke to do that.\n",
        "tokenizer = Tokenizer(num_words=10_000)\n",
        "tokenizer.fit_on_texts(train['text_cleaned'])\n",
        "sequences =tokenizer.texts_to_sequences(train['text_cleaned'])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=25) # determined this by finding the max len of a sequence\n",
        "labels = np.asarray(train['target'])\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmV8xS54ARSj",
        "outputId": "56c0559a-4ba6-48fb-befb-5c62c78520b9"
      },
      "id": "cmV8xS54ARSj",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13809 unique tokens.\n",
            "Shape of data tensor: (7613, 25)\n",
            "Shape of label tensor: (7613,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xznyoslNLyDN",
        "outputId": "c6bc1e54-b0fb-4353-b7a7-a3d367d3647a"
      },
      "id": "xznyoslNLyDN",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13809"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max([len(s) for s in sequences])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5O6zcb7N8f0",
        "outputId": "2ab98a21-5794-421c-96b0-04e81357badc"
      },
      "id": "z5O6zcb7N8f0",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the embedding layer\n",
        "\n",
        "text file with glove embeddings gotten from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)"
      ],
      "metadata": {
        "id": "3S3itDhiELZx"
      },
      "id": "3S3itDhiELZx"
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {} # creating a dictionary\n",
        "\n",
        "glove_path = 'glove.twitter.27B.25d.txt'\n",
        "\n",
        "\n",
        "with open(glove_path, encoding='utf-8') as glove_file:\n",
        "    for line in glove_file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ejWNXrjARLw",
        "outputId": "f91c52e3-16ea-46d4-f0f5-6cd27a4f5c5e"
      },
      "id": "-ejWNXrjARLw",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1193514 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ok now there we have an embeddings dictionary where the keys are the 1,193,514 unique words and the values are the 25 dimension vectors that each word is represented by"
      ],
      "metadata": {
        "id": "HmDf6xLPHUiO"
      },
      "id": "HmDf6xLPHUiO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point we can leverage our embedding_index dictionary and our word_index to compute our embedding matrix:\n"
      ],
      "metadata": {
        "id": "jwu2Um2TNlO0"
      },
      "id": "jwu2Um2TNlO0"
    },
    {
      "cell_type": "code",
      "source": [
        "num_words_in_glove = 0\n",
        "embedding_dim= 25\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        num_words_in_glove +=1\n",
        "print(f'Total number of words from Glove: {num_words_in_glove}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUh0J_N3GseS",
        "outputId": "ee9b2281-df0e-4157-e96f-451e9e8c4d44"
      },
      "id": "nUh0J_N3GseS",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words from Glove: 12326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roIHIifcPPWz",
        "outputId": "05a5b7b2-83e7-44ec-a454-8306ad534cf6"
      },
      "id": "roIHIifcPPWz",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13810, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding_matrix is now filled with a mapping of words(tokens) from our corpus into the vectors from GloVe"
      ],
      "metadata": {
        "id": "095zfJXoO7A1"
      },
      "id": "095zfJXoO7A1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras LSTM"
      ],
      "metadata": {
        "id": "JbT71SIoQl79"
      },
      "id": "JbT71SIoQl79"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, # padded sequences where the words are tokenized with tokenizer.word_index\n",
        "    labels, # np.asarray(train['target'])\n",
        "    random_state = 214,\n",
        "    stratify=labels\n",
        "    )"
      ],
      "metadata": {
        "id": "7H0mUG9vC3aY"
      },
      "id": "7H0mUG9vC3aY",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98bwsuP9gOCN",
        "outputId": "1e1536fb-873f-4de6-fdf9-a1ae261eebba"
      },
      "id": "98bwsuP9gOCN",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index) + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yst4k043RVev",
        "outputId": "06b3f9cd-0136-4a73-d12b-fbc23be85b55"
      },
      "id": "yst4k043RVev",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13810"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import kernel_metrics\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, # input dim = max_words\n",
        "                    embedding_dim, # output dim = dim of glove vectors\n",
        "                    input_length=25, # input_length=max_sequence_length\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False)\n",
        ")\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
        "model.add(Conv1D(filters = 128,kernel_size=3, activation='relu'))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M9RzwZ5Qltc",
        "outputId": "5d1d373e-58f6-411c-edad-fb29b01909fd"
      },
      "id": "8M9RzwZ5Qltc",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 25, 25)            345250    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 25, 25)            0         \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 25, 256)           157696    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 23, 128)           98432     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 609699 (2.33 MB)\n",
            "Trainable params: 264449 (1.01 MB)\n",
            "Non-trainable params: 345250 (1.32 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train,\n",
        "          y_train,\n",
        "          validation_data = (X_test, y_test),\n",
        "          epochs=20,\n",
        "          batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUHuielmQlrR",
        "outputId": "2c4a1d7b-fcb9-40ea-ba27-3bb82c8f3e88"
      },
      "id": "CUHuielmQlrR",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "179/179 [==============================] - 24s 102ms/step - loss: 0.5251 - accuracy: 0.7455 - val_loss: 0.5015 - val_accuracy: 0.7616\n",
            "Epoch 2/20\n",
            "179/179 [==============================] - 21s 116ms/step - loss: 0.5057 - accuracy: 0.7665 - val_loss: 0.4892 - val_accuracy: 0.7663\n",
            "Epoch 3/20\n",
            "179/179 [==============================] - 17s 95ms/step - loss: 0.4961 - accuracy: 0.7700 - val_loss: 0.4584 - val_accuracy: 0.7952\n",
            "Epoch 4/20\n",
            "179/179 [==============================] - 21s 120ms/step - loss: 0.4792 - accuracy: 0.7775 - val_loss: 0.4625 - val_accuracy: 0.7831\n",
            "Epoch 5/20\n",
            "179/179 [==============================] - 18s 102ms/step - loss: 0.4804 - accuracy: 0.7796 - val_loss: 0.4572 - val_accuracy: 0.7973\n",
            "Epoch 6/20\n",
            "179/179 [==============================] - 17s 97ms/step - loss: 0.4829 - accuracy: 0.7751 - val_loss: 0.4701 - val_accuracy: 0.7857\n",
            "Epoch 7/20\n",
            "179/179 [==============================] - 18s 103ms/step - loss: 0.4712 - accuracy: 0.7812 - val_loss: 0.4390 - val_accuracy: 0.7999\n",
            "Epoch 8/20\n",
            "179/179 [==============================] - 17s 98ms/step - loss: 0.4716 - accuracy: 0.7774 - val_loss: 0.4583 - val_accuracy: 0.7873\n",
            "Epoch 9/20\n",
            "179/179 [==============================] - 18s 102ms/step - loss: 0.4737 - accuracy: 0.7803 - val_loss: 0.4326 - val_accuracy: 0.8057\n",
            "Epoch 10/20\n",
            "179/179 [==============================] - 18s 103ms/step - loss: 0.4662 - accuracy: 0.7828 - val_loss: 0.4422 - val_accuracy: 0.7988\n",
            "Epoch 11/20\n",
            "179/179 [==============================] - 18s 99ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4388 - val_accuracy: 0.8046\n",
            "Epoch 12/20\n",
            "179/179 [==============================] - 17s 96ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.4280 - val_accuracy: 0.8041\n",
            "Epoch 13/20\n",
            "179/179 [==============================] - 18s 102ms/step - loss: 0.4574 - accuracy: 0.7912 - val_loss: 0.4264 - val_accuracy: 0.8093\n",
            "Epoch 14/20\n",
            "179/179 [==============================] - 18s 102ms/step - loss: 0.4500 - accuracy: 0.7914 - val_loss: 0.4244 - val_accuracy: 0.8051\n",
            "Epoch 15/20\n",
            "179/179 [==============================] - 18s 101ms/step - loss: 0.4513 - accuracy: 0.7959 - val_loss: 0.4425 - val_accuracy: 0.7962\n",
            "Epoch 16/20\n",
            "179/179 [==============================] - 20s 110ms/step - loss: 0.4564 - accuracy: 0.7900 - val_loss: 0.4365 - val_accuracy: 0.8015\n",
            "Epoch 17/20\n",
            "179/179 [==============================] - 17s 96ms/step - loss: 0.4503 - accuracy: 0.7930 - val_loss: 0.4369 - val_accuracy: 0.7946\n",
            "Epoch 18/20\n",
            "179/179 [==============================] - 18s 103ms/step - loss: 0.4428 - accuracy: 0.7980 - val_loss: 0.4311 - val_accuracy: 0.8004\n",
            "Epoch 19/20\n",
            "179/179 [==============================] - 19s 108ms/step - loss: 0.4339 - accuracy: 0.8057 - val_loss: 0.4278 - val_accuracy: 0.8057\n",
            "Epoch 20/20\n",
            "179/179 [==============================] - 17s 95ms/step - loss: 0.4424 - accuracy: 0.7945 - val_loss: 0.4231 - val_accuracy: 0.8136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ok, a 81.36% test accuracy and 79.45% train accuracy is good enough for streamlit app. I'll pickle this model, and tokenizer. and see if I can create the streamlit app"
      ],
      "metadata": {
        "id": "g6lK-rvXZVcn"
      },
      "id": "g6lK-rvXZVcn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### first, testing to see if model.predict works as expected for just 1 tweet"
      ],
      "metadata": {
        "id": "jY-lTOuBahr9"
      },
      "id": "jY-lTOuBahr9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "a function to clean tweets and put them in a format for the model to predict with"
      ],
      "metadata": {
        "id": "vBP9TacbnmSt"
      },
      "id": "vBP9TacbnmSt"
    },
    {
      "cell_type": "code",
      "source": [
        "def tweet_to_input(tweet,tokenizer=tokenizer):\n",
        "  '''\n",
        "  Function that transforms asingle tweet(string) into an input for the model that was trained with a particular tokenizer\n",
        "  input: tweet = single tweet that is a string\n",
        "         tokenizer = tensorflow tokenizer used to train the model that we are getting predicitons from\n",
        "\n",
        "  output: input array for model of shape (,max_padded_sequence_length)  aka (1,25) for this particular model\n",
        "\n",
        "  requires:\n",
        "            - tweet_cleaner() custom function\n",
        "            - tensorflow.keras.preprocessing.Tokenizer object that was used in model training\n",
        "            - pad_sequences() function from tensorflow.keras.preprocessing.sequence\n",
        "\n",
        "  '''\n",
        "\n",
        "  cleaned_tweet = list(map(tweet_cleaner,[tweet]))\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences(cleaned_tweet)\n",
        "\n",
        "  padded_array = pad_sequences(sequence, maxlen=25)\n",
        "\n",
        "  return padded_array\n",
        "\n"
      ],
      "metadata": {
        "id": "4pu9ALvYjvQN"
      },
      "id": "4pu9ALvYjvQN",
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = tweet_to_input(\"Israel-Hamas war rages as Palestinian death toll rises in Gaza: Live updates\" ,tokenizer=tokenizer)\n",
        "\n",
        "model.predict(inp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gatywybwmpYd",
        "outputId": "d21f23c9-489e-4d3e-84d5-1cf0bb973d5c"
      },
      "id": "gatywybwmpYd",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9823281]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('arjun_model_2.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "with open('tokenizer_arjun_v1.pkl', 'wb') as file:\n",
        "    pickle.dump(tokenizer, file)\n"
      ],
      "metadata": {
        "id": "sMVgm8EPZ6sM"
      },
      "id": "sMVgm8EPZ6sM",
      "execution_count": 143,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}